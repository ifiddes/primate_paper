{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "from tools.fileOps import *\n",
    "from tools.procOps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constructed the transcript files\n",
    "m = {}\n",
    "# first, the CAT annotations\n",
    "for g in ['Clint_Chimp', 'Susie_Gorilla', 'Susie_Orangutan']:\n",
    "    gp = '../../consensus_gene_set/{}.filtered.gp'.format(g)\n",
    "    fa = '../../genome_files/{}.fa'.format(g)\n",
    "    with TemporaryFilePath() as tmp:\n",
    "        !genePredToBed {gp} {tmp}\n",
    "        !bedtools getfasta -fi {fa} -bed {tmp} -fo {g + '.CAT.transcripts.fa'} -name -split -s\n",
    "    m[(g.replace('_', '/'), 'CAT')] = g + '.CAT.transcripts.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CAT annotations for original primates, fix names\n",
    "og_dir = '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/'\n",
    "for g, og in zip(*[['Chimp', 'Gorilla', 'Orangutan'], ['panTro4', 'gorGor4', 'ponAbe2']]):\n",
    "    gp = os.path.join(og_dir, 'consensus_gene_set', g + '.filtered.gp')\n",
    "    fa = os.path.join(og_dir, 'genome_files', g + '.fa')\n",
    "    with TemporaryFilePath() as tmp:\n",
    "        !genePredToBed {gp} {tmp}\n",
    "        !bedtools getfasta -fi {fa} -bed {tmp} -fo {og + '.CAT.transcripts.fa'} -name -split -s\n",
    "    m[(og, 'CAT')] = og + '.CAT.transcripts.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# human, which CAT already produces\n",
    "!cp ../../reference/gencode.v27.annotation.no_PAR.fa ./\n",
    "m[('Human', 'GENCODE V27')] = 'gencode.v27.annotation.no_PAR.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index file chimp_gorilla_fasta/gorilla_gorilla_softmasked_toplevel.fa.fixed.fai not found, generating...\n",
      "Feature (CABD030151935.1:1777-2008) beyond the length of CABD030151935.1 size (2000 bp).  Skipping.\n",
      "Feature (CABD030151492.1:1938-2009) beyond the length of CABD030151492.1 size (2000 bp).  Skipping.\n",
      "Feature (CABD030130636.1:1218-1325) beyond the length of CABD030130636.1 size (1322 bp).  Skipping.\n",
      "Feature (CABD030130064.1:746-923) beyond the length of CABD030130064.1 size (913 bp).  Skipping.\n",
      "Feature (CABD030151826.1:800-900) beyond the length of CABD030151826.1 size (894 bp).  Skipping.\n",
      "Feature (CABD030151588.1:765-872) beyond the length of CABD030151588.1 size (870 bp).  Skipping.\n",
      "Feature (CABD030161071.1:739-831) beyond the length of CABD030161071.1 size (818 bp).  Skipping.\n",
      "index file chimp_gorilla_fasta/pan_troglodytes_softmasked_toplevel.fa.fixed.fai not found, generating...\n",
      "Feature (KV421959.1:10660-10764) beyond the length of KV421959.1 size (10756 bp).  Skipping.\n",
      "Feature (AACZ04043439.1:1309-1416) beyond the length of AACZ04043439.1 size (1400 bp).  Skipping.\n",
      "Feature (AACZ04052657.1:1219-1326) beyond the length of AACZ04052657.1 size (1310 bp).  Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Ensembl V91 for chimp and gorilla\n",
    "!gtfToGenePred -genePredExt Pan_troglodytes.Pan_tro_3.0.91.gtf /dev/stdout | genePredToBed /dev/stdin Pan_troglodytes.Pan_tro_3.0.91.bed\n",
    "!gtfToGenePred -genePredExt Gorilla_gorilla.gorGor4.91.gtf /dev/stdout | genePredToBed /dev/stdin Gorilla_gorilla.gorGor4.91.bed\n",
    "!bedtools getfasta -fi chimp_gorilla_fasta/gorilla_gorilla_softmasked_toplevel.fa.fixed -bed Gorilla_gorilla.gorGor4.91.bed -name -split -s -fo gorGor4.Ensembl.transcripts.fa \n",
    "!bedtools getfasta -fi chimp_gorilla_fasta/pan_troglodytes_softmasked_toplevel.fa.fixed -bed Pan_troglodytes.Pan_tro_3.0.91.bed -name -split -s -fo panTro4.Ensembl.transcripts.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m[('gorGor4', 'Ensembl V91')] = 'gorGor4.Ensembl.transcripts.fa'\n",
    "m[('panTro4', 'Ensembl V91')] = 'panTro4.Ensembl.transcripts.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finally, we need to load the ensembl original annotations\n",
    "# for orangutan, things are easier\n",
    "with TemporaryFilePath() as tmp:\n",
    "    g = 'Orangutan'\n",
    "    og = 'ponAbe2'\n",
    "    fa = os.path.join(og_dir, 'genome_files', g + '.fa')\n",
    "    !gtfToGenePred -genePredExt Pongo_abelii.PPYG2.88.gtf /dev/stdout | genePredToBed /dev/stdin {tmp}\n",
    "    !bedtools getfasta -fi {fa} -bed {tmp} -fo {og + '.ensembl.transcripts.fa'} -name -split -s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m[('ponAbe2', 'Ensembl V90')] = og + '.ensembl.transcripts.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now, we can construct our kallisto indices\n",
    "\n",
    "!mkdir indices -p\n",
    "\n",
    "import os\n",
    "index_map = {}\n",
    "with open('cmds.txt', 'w') as outf:\n",
    "    for (g, a), x in m.iteritems():\n",
    "        o = '_'.join([g.replace('/', '_'), a.replace(' ', '_')])\n",
    "        cmd = 'kallisto index -i indices/{}.kallisto {}\\n'.format(o, x)\n",
    "        outf.write(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cmd=\"cd ${PWD} && para make -cpu=1 -ram=32g cmds.txt\"\n",
    "ssh ku $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map of fastq names to genome names\n",
    "fq_map = {'panTro4': 'chimp', 'ponAbe2': 'orang', 'Human': 'human', 'gorGor3': 'gorilla', 'gorGor4': 'gorilla',\n",
    "         'Susie/Gorilla': 'gorilla', 'Clint/Chimp': 'chimp', 'Susie/Orangutan': 'orang'}\n",
    "\n",
    "with open('kallisto_cmds.txt', 'w') as outf:\n",
    "    for (g, a), x in m.iteritems():\n",
    "        fwd = 'fastqs/' + fq_map[g] + '.fwd.fq'\n",
    "        rev = 'fastqs/' + fq_map[g] + '.rev.fq'\n",
    "        o = '_'.join([g.replace('/', '_'), a.replace(' ', '_')])\n",
    "        index = 'indices/' + o + '.kallisto'\n",
    "        cmd = 'kallisto quant -t 8 -o {} -i {} {} {}\\n'.format(o, index, fwd, rev)\n",
    "        outf.write(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking input files\n",
      "10 jobs written to /hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/primate_paper/kallisto_expression/batch\n",
      "10 jobs in batch\n",
      "0 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "Pushed Jobs: 10\n",
      "================\n",
      "Checking job status 0 minutes after launch\n",
      "10 jobs in batch\n",
      "10 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 1 minutes after launch\n",
      "10 jobs in batch\n",
      "10 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 2 minutes after launch\n",
      "10 jobs in batch\n",
      "10 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 3 minutes after launch\n",
      "10 jobs in batch\n",
      "9 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 4 minutes after launch\n",
      "10 jobs in batch\n",
      "8 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 5 minutes after launch\n",
      "10 jobs in batch\n",
      "5 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 7 minutes after launch\n",
      "10 jobs in batch\n",
      "2 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 9 minutes after launch\n",
      "10 jobs in batch\n",
      "2 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 11 minutes after launch\n",
      "10 jobs in batch\n",
      "1 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 14 minutes after launch\n",
      "10 jobs in batch\n",
      "1 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "================\n",
      "Checking job status 17 minutes after launch\n",
      "10 jobs in batch\n",
      "73711 jobs (including everybody's) in Parasol queue or running.\n",
      "Checking finished jobs\n",
      "updated job database on disk\n",
      "Successful batch!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cmd=\"cd ${PWD} && para make -cpu=1 -ram=32g kallisto_cmds.txt\"\n",
    "ssh ku $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "dfs = {}\n",
    "for g, a in m:\n",
    "    o = '_'.join([g.replace('/', '_'), a.replace(' ', '_')])\n",
    "    df = pd.read_csv(os.path.join(o, 'abundance.tsv'), sep='\\t')\n",
    "    df['target_id'] = [x.split('(')[0] for x in df['target_id']]\n",
    "    dfs[(g, a)] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start combining\n",
    "\n",
    "from tools.bio import *\n",
    "from tools.transcripts import *\n",
    "from tools.sqlInterface import *\n",
    "from tools.gff3 import *\n",
    "from tools.misc import *\n",
    "from collections import *\n",
    "\n",
    "# load name maps\n",
    "gtfs = {('panTro4', 'Ensembl V91'): 'Pan_troglodytes.Pan_tro_3.0.91.gtf',\n",
    "     ('gorGor4', 'Ensembl V91'): 'Gorilla_gorilla.gorGor4.91.gtf',\n",
    "     ('ponAbe2', 'Ensembl V90'): 'Pongo_abelii.PPYG2.88.gtf',\n",
    "     ('panTro4', 'CAT'): '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/consensus_gene_set/Chimp.filtered.gp_info',\n",
    "     ('gorGor4', 'CAT'): '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/consensus_gene_set/Gorilla.filtered.gp_info',\n",
    "     ('ponAbe2', 'CAT'): '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/consensus_gene_set/Orangutan.filtered.gp_info',\n",
    "     ('Clint/Chimp', 'CAT'): '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/consensus_gene_set/Clint_Chimp.fixed.filtered.gp_info',\n",
    "     ('Susie/Gorilla', 'CAT'): '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/consensus_gene_set/Susie_Gorilla.fixed.filtered.gp_info',\n",
    "    ('Susie/Orangutan', 'CAT'): '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/consensus_gene_set/Susie_Orangutan.fixed.filtered.gp_info',\n",
    "    ('Human', 'GENCODE V27'): '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/reference/gencode.v27.annotation.no_PAR.gtf'}\n",
    "\n",
    "def construct_ensembl_map(gtf):\n",
    "    lines = [x.split('\\t') for x in open(gtf) if not x.startswith('#')]\n",
    "    ensembl_map = []\n",
    "    for l in lines:\n",
    "        x = parse_gtf_attr_line(l[-1])\n",
    "        try:\n",
    "            ensembl_map.append([x['gene_id'], x['transcript_id']])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return pd.DataFrame(ensembl_map, columns=['gene_id', 'transcript_id'])\n",
    "\n",
    "\n",
    "name_dfs = defaultdict(dict)\n",
    "for (g, a), gtf in gtfs.iteritems():\n",
    "    if g == 'Human':\n",
    "        name_dfs[(g, a)] = load_annotation('/hive/groups/recon/projs/primates/susie_indel_corrected/databases/Human.db')\n",
    "        name_dfs[(g, a)] = name_dfs[(g, a)][['TranscriptId', 'GeneId']].drop_duplicates()\n",
    "        name_dfs[(g, a)].columns = ['transcript_id', 'gene_id']\n",
    "    elif 'Ensembl' in a:\n",
    "        name_dfs[(g, a)] = construct_ensembl_map(gtf)\n",
    "    else:\n",
    "        gp_info = gtf\n",
    "        df = pd.read_csv(gp_info, sep='\\t', header=0)[['gene_id', 'transcript_id']].drop_duplicates()\n",
    "        df.columns = ['gene_id', 'transcript_id']\n",
    "        name_dfs[(g, a)] = df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_dfs = {}\n",
    "for x, name_df in name_dfs.iteritems():\n",
    "    df = dfs[x]\n",
    "    merged = df.merge(name_df, left_on='target_id', right_on='transcript_id')\n",
    "    combined_dfs[x] = merged.drop(['target_id', 'length', 'eff_length', 'est_counts'], axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_by_gene = {}\n",
    "for x, df in combined_dfs.iteritems():\n",
    "    combined_by_gene[x] = df.drop(['transcript_id'], axis=1).groupby('gene_id').aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn this into a flat dataframe with the columns Assembly/Annotation, total, expressed\n",
    "import numpy as np\n",
    "order = ['Human (GENCODE V27)', 'panTro4 (Ensembl V91)', 'panTro4 (CAT)', 'Clint/Chimp (CAT)',\n",
    "         'gorGor4 (Ensembl V91)', 'gorGor4 (CAT)', 'Susie/Gorilla (CAT)',\n",
    "         'ponAbe2 (Ensembl V90)', 'ponAbe2 (CAT)', 'Susie/Orangutan (CAT)',\n",
    "         ]\n",
    "\n",
    "\n",
    "r = []\n",
    "for x, df in combined_by_gene.iteritems():\n",
    "    r.append(['{} ({})'.format(*x), len(df) - len(df[df.tpm > 0.1]), len(df[df.tpm > 0.1])])\n",
    "gene_df = pd.DataFrame(r, columns=['Assembly/Annotation', 'not_expressed', 'expressed'])\n",
    "gene_df['Assembly/Annotation'] = pd.Categorical(gene_df['Assembly/Annotation'], order, ordered=True)\n",
    "gene_df = gene_df.sort_values('Assembly/Annotation')\n",
    "\n",
    "gene_data = np.array(gene_df[['expressed', 'not_expressed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now by transcript\n",
    "# turn this into a flat dataframe with the columns Assembly/Annotation, total, expressed\n",
    "import numpy as np\n",
    "\n",
    "r = []\n",
    "for x, df in combined_dfs.iteritems():\n",
    "    r.append(['{} ({})'.format(*x), len(df) - len(df[df.tpm > 0.1]), len(df[df.tpm > 0.1])])\n",
    "tx_df = pd.DataFrame(r, columns=['Assembly/Annotation', 'not_expressed', 'expressed'])\n",
    "tx_df['Assembly/Annotation'] = pd.Categorical(tx_df['Assembly/Annotation'], order, ordered=True)\n",
    "tx_df = tx_df.sort_values('Assembly/Annotation')\n",
    "\n",
    "tx_data = np.array(tx_df[['expressed', 'not_expressed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "palette=[\"#CDBA74\", \n",
    "         '#89bfdd', '#549ece', '#2b7bbb',\n",
    "         '#fd8262', '#f54f39', '#d62221',\n",
    "         '#8fd18c', '#57b668', '#2c954c',\n",
    "         ]\n",
    "\n",
    "from cat.plots import *\n",
    "# plot it\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "majorLocator = MultipleLocator(10000)\n",
    "minorLocator = MultipleLocator(2500)\n",
    "mkfunc = lambda x, pos: '{}k'.format(int(float(x) / 1000))\n",
    "mkformatter = matplotlib.ticker.FuncFormatter(mkfunc)\n",
    "with open('expressed_ipsc_kallisto.pdf', 'w') as outf, PdfPages(outf) as pdf:\n",
    "    bar_width = 0.6\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(8, 3), ncols=2)\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(10000))\n",
    "    ax1.xaxis.set_major_formatter(mkformatter)\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(2500))\n",
    "    ax2.xaxis.set_major_locator(MultipleLocator(25000))\n",
    "    ax2.xaxis.set_major_formatter(mkformatter)\n",
    "    ax2.xaxis.set_minor_locator(MultipleLocator(5000))\n",
    "    for i, (exp, not_exp) in enumerate(gene_data):\n",
    "        b = ax1.barh(i, exp, left=0, height=bar_width, alpha=0.9, linewidth=0, color=palette[i])\n",
    "        b = ax1.barh(i, not_exp, left=exp, height=bar_width, hatch='//', alpha=0.45, ecolor='black',\n",
    "                   linewidth=0, color=palette[i])\n",
    "    for i, (exp, not_exp) in enumerate(tx_data):\n",
    "        b = ax2.barh(i, exp, left=0, height=bar_width, alpha=0.9, linewidth=0, color=palette[i])\n",
    "        b = ax2.barh(i, not_exp, left=exp, height=bar_width, hatch='//', alpha=0.45, ecolor='black',\n",
    "                   linewidth=0, color=palette[i])\n",
    "\n",
    "    sns.despine()\n",
    "    ax1.set_yticks(np.arange(len(tx_df)) + (bar_width / 2))\n",
    "    ax2.set_yticks(np.arange(len(tx_df)) + (bar_width / 2))\n",
    "    ax2.set_yticklabels('')\n",
    "    ax1.set_yticklabels(list(tx_df['Assembly/Annotation']))\n",
    "    ax2.set_xlabel('Number of transcripts')\n",
    "    ax1.set_xlabel('Number of genes')\n",
    "    fig.suptitle('Non-zero expression estimates of species-specific iPSC RNA-seq (Kallisto)')\n",
    "    multipage_close(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Assembly/Annotation  not_expressed  expressed\n",
      "8    Human (GENCODE V27)          29986      27090\n",
      "1  panTro4 (Ensembl V91)          11595      20353\n",
      "2          panTro4 (CAT)          27564      28039\n",
      "3      Clint/Chimp (CAT)          27925      27969\n",
      "9  gorGor4 (Ensembl V91)          10408      19188\n",
      "0          gorGor4 (CAT)          27345      27819\n",
      "7    Susie/Gorilla (CAT)          28418      27567\n",
      "5  ponAbe2 (Ensembl V90)          13068      15338\n",
      "4          ponAbe2 (CAT)          34557      19945\n",
      "6  Susie/Orangutan (CAT)          35179      20043\n"
     ]
    }
   ],
   "source": [
    "print gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some info on orangutan genes missing for comparison.\n",
    "\n",
    "orang_old = combined_by_gene[('ponAbe2', 'Ensembl V90')].reset_index()\n",
    "orang_new = combined_by_gene[('ponAbe2', 'CAT')].reset_index()\n",
    "orang_old_not_expressed = set(orang_old[orang_old.tpm <= 0.1].gene_id)\n",
    "orang_new_not_expressed = set(orang_new[orang_new.tpm <= 0.1].gene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def construct_ensembl_map_gene_name(gtf):\n",
    "    lines = [x.split('\\t') for x in open(gtf) if not x.startswith('#')]\n",
    "    ensembl_map = []\n",
    "    for l in lines:\n",
    "        x = parse_gtf_attr_line(l[-1])\n",
    "        try:\n",
    "            ensembl_map.append([x['gene_id'], x['transcript_id'], x['gene_name'], x['gene_biotype']])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return pd.DataFrame(ensembl_map, columns=['gene_id', 'transcript_id', 'gene_name', 'gene_biotype'])\n",
    "\n",
    "ponabe = construct_ensembl_map_gene_name('Pongo_abelii.PPYG2.88.gtf')\n",
    "human = load_annotation('/hive/groups/recon/projs/primates/susie_indel_corrected/databases/Human.db')\n",
    "ponabe_new = pd.read_csv('/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/consensus_gene_set/Orangutan.gp_info', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orang_m = ponabe[ponabe.gene_id.isin(orang_old_not_expressed)].drop_duplicates()\n",
    "orang_new_m = ponabe_new[ponabe_new.gene_id.isin(orang_new_not_expressed)]\n",
    "orang_new_m = orang_new_m[['gene_id', 'gene_biotype']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Assembly/Annotation  not_expressed  expressed\n",
      "8    Human (GENCODE V27)          98010      95584\n",
      "1  panTro4 (Ensembl V91)          23172      35191\n",
      "2          panTro4 (CAT)          95857      93694\n",
      "3      Clint/Chimp (CAT)          97870      94855\n",
      "9  gorGor4 (Ensembl V91)          20924      32072\n",
      "0          gorGor4 (CAT)          94744      93659\n",
      "7    Susie/Gorilla (CAT)          98453      94281\n",
      "5  ponAbe2 (Ensembl V90)          13472      15938\n",
      "4          ponAbe2 (CAT)         129576      57416\n",
      "6  Susie/Orangutan (CAT)         132546      58170\n"
     ]
    }
   ],
   "source": [
    "print tx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
