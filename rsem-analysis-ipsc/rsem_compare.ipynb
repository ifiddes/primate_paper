{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## construct references\n",
    "annotations = {'human': '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/reference/gencode.v27.annotation.no_PAR.gtf',\n",
    "              'orangutan': '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/consensus_gene_set/Susie_Orangutan.filtered.gtf',\n",
    "              'chimp': '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/consensus_gene_set/Clint_Chimp.filtered.gtf',\n",
    "              'gorilla': '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/consensus_gene_set/Susie_Gorilla.filtered.gtf',\n",
    "              'ponAbe2': '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/consensus_gene_set/Orangutan.filtered.gtf',\n",
    "              'panTro4': '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/consensus_gene_set/Chimp.filtered.gtf',\n",
    "              'gorGor4': '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/consensus_gene_set/Gorilla.filtered.gtf'}\n",
    "\n",
    "fastas = {'human': '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/genome_files/Human.fa',\n",
    "         'orangutan': '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/genome_files/Susie_Orangutan.fa',\n",
    "         'chimp': '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/genome_files/Clint_Chimp.fa',\n",
    "         'gorilla': '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/genome_files/Susie_Gorilla.fa',\n",
    "         'ponAbe2': '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/genome_files/Orangutan.fa',\n",
    "         'panTro4': '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/genome_files/Chimp.fa',\n",
    "         'gorGor4': '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/genome_files/Gorilla.fa'}\n",
    "\n",
    "base_cmd = 'rsem-prepare-reference --star -p 32 --gtf {0} {1} {2}/{2}\\n'\n",
    "with open('cmds.txt', 'w') as outf:\n",
    "    for g, a in annotations.iteritems():\n",
    "        f = fastas[g]\n",
    "        !mkdir -p {g}\n",
    "        outf.write(base_cmd.format(a, f, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cmd=\"cd ${PWD} && para make -cpu=32 -ram=256g cmds.txt\"\n",
    "ssh ku $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "rnaseq_dir = '/hive/groups/recon/projs/primates/more_rnaseq_data/iPSC-data'\n",
    "base_cmd = 'rsem-calculate-expression -p 32 --star --paired-end {0} {1} {2}/{2} {2}\\n'\n",
    "with open('cmds.txt', 'w') as outf:\n",
    "    for g in ['human', 'orangutan', 'chimp', 'gorilla']:\n",
    "        fwd = os.path.join(rnaseq_dir, g + '.fwd.fq')\n",
    "        rev = os.path.join(rnaseq_dir, g + '.rev.fq')\n",
    "        assert os.path.exists(fwd)\n",
    "        assert os.path.exists(rev)\n",
    "        outf.write(base_cmd.format(fwd, rev, g))\n",
    "    # add in the original genome CAT sets\n",
    "    for g, ref in [['chimp', 'panTro4'], ['gorilla', 'gorGor4'], ['orangutan', 'ponAbe2']]:\n",
    "        fwd = os.path.join(rnaseq_dir, g + '.fwd.fq')\n",
    "        rev = os.path.join(rnaseq_dir, g + '.rev.fq')\n",
    "        assert os.path.exists(fwd)\n",
    "        assert os.path.exists(rev)\n",
    "        outf.write(base_cmd.format(fwd, rev, ref))\n",
    "    # add in the ensembl sets\n",
    "    for g, ref in [['chimp', 'pantro_ensembl'], ['gorilla', 'gorgor3_ensembl'], ['orangutan', 'ponabe_ensembl']]:\n",
    "        fwd = os.path.join(rnaseq_dir, g + '.fwd.fq')\n",
    "        rev = os.path.join(rnaseq_dir, g + '.rev.fq')\n",
    "        assert os.path.exists(fwd)\n",
    "        assert os.path.exists(rev)\n",
    "        outf.write(base_cmd.format(fwd, rev, ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hack to finish EM step, can't run on cluster\n",
    "import os\n",
    "base_cmd = 'rsem-calculate-expression --alignments -p 4 --paired-end {0}.temp/{0}.bam {0}/{0} {0}\\n'\n",
    "with open('cmds_tmp.txt', 'w') as outf:\n",
    "    for g in ['human', 'orangutan', 'chimp', 'gorilla', 'panTro4', 'ponAbe2', 'pantro_ensembl',\n",
    "             'gorgor3_ensembl', 'ponabe_ensembl', 'gorGor4']:\n",
    "        outf.write(base_cmd.format(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cmd=\"cd ${PWD} && para make -cpu=32 -ram=256g cmds.txt\"\n",
    "ssh ku $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load dfs\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = '/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/consensus_gene_set/'\n",
    "dfs = {'chimp': pd.read_csv(os.path.join(base_dir, 'Clint_Chimp.fixed.filtered.gp_info'), sep='\\t'),\n",
    "      'oranguatan': pd.read_csv(os.path.join(base_dir, 'Susie_Orangutan.fixed.filtered.gp_info'), sep='\\t'),\n",
    "      'gorilla': pd.read_csv(os.path.join(base_dir, 'Susie_Gorilla.fixed.filtered.gp_info'), sep='\\t')}\n",
    "\n",
    "base_dir = '/hive/groups/recon/projs/primates/original_primates/redo_annotation_indel/consensus_gene_set/'\n",
    "for g, og in [['panTro4', 'Chimp'], ['ponAbe2', 'Orangutan'], ['gorGor4', 'Gorilla']]:\n",
    "    dfs[g] = pd.read_csv(os.path.join(base_dir, og + '.filtered.gp_info'), sep='\\t')\n",
    "\n",
    "from tools.sqlInterface import *\n",
    "dfs['human'] = load_annotation('/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/databases/Human.db')\n",
    "dfs['human'].columns = ['transcript_id', 'gene_id', 'transcript_name', 'gene_name', 'gene_biotype', 'transcript_biotype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load ensembl annotations\n",
    "from tools.misc import *\n",
    "from glob import glob\n",
    "def load_map(gtf):\n",
    "    r = []\n",
    "    for l in open(gtf):\n",
    "        l = l.rstrip().split('\\t')\n",
    "        x = parse_gtf_attr_line(l[-1])\n",
    "        if 'gene_name' not in x:\n",
    "            continue\n",
    "        r.append([x['gene_id'], x['gene_name'], x['gene_biotype']])\n",
    "    m = pd.DataFrame(r, columns=['gene_id', 'gene_name', 'gene_biotype'])\n",
    "    m = m.drop_duplicates()\n",
    "    return m\n",
    "\n",
    "\n",
    "for ref in ['pantro_ensembl', 'gorgor3_ensembl', 'ponabe_ensembl']:\n",
    "    gtf = glob(ref + '/*gtf')\n",
    "    assert len(gtf) == 1\n",
    "    gtf = gtf[0]\n",
    "    df = load_map(gtf)\n",
    "    dfs[ref] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load expression\n",
    "exp_dfs = {}\n",
    "for g in dfs:\n",
    "    if 'ponAbe' in g or 'ponabe' in g or 'oranguatan' in g:\n",
    "        continue\n",
    "    exp_dfs[g] = pd.read_csv('{}.genes.results'.format(g), header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gorGor4 824882.46\n",
      "panTro4 805766.72\n",
      "chimp 573281.86\n",
      "gorilla 681951.36\n",
      "human 605480.73\n",
      "gorgor3_ensembl 689211.39\n",
      "pantro_ensembl 708656.08\n"
     ]
    }
   ],
   "source": [
    "# merge dfs\n",
    "merged_dfs = {}\n",
    "for g, exp_df in exp_dfs.iteritems():\n",
    "    if g == 'human' or 'ensembl' in g:\n",
    "        m = exp_df.merge(dfs[g][['gene_id', 'gene_name', 'gene_biotype']].drop_duplicates(), on='gene_id')\n",
    "        m = m[m.gene_biotype == 'protein_coding']\n",
    "        m = m[['gene_name', 'TPM']]\n",
    "    else:\n",
    "        m = exp_df.merge(dfs[g][['gene_id', 'source_gene_common_name', 'gene_biotype']].drop_duplicates(), on='gene_id')\n",
    "        m = m[m.gene_biotype == 'protein_coding']\n",
    "        m = m[['source_gene_common_name', 'TPM']]\n",
    "        m.columns = ['gene_name', 'TPM']\n",
    "    m = m.groupby('gene_name').aggregate(sum)\n",
    "    merged_dfs[g] = m.reset_index()\n",
    "    print g, m.TPM.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix names\n",
    "merged_dfs['human'].columns = ['gene_name', 'Human (GENCODE V27)']\n",
    "merged_dfs['chimp'].columns = ['gene_name', 'Clint/Chimpanzee (CAT)']\n",
    "merged_dfs['gorilla'].columns = ['gene_name', 'Susie/Gorilla (CAT)']\n",
    "#merged_dfs['orangutan'].columns = ['gene_name', 'Susie/Orangutan (CAT)']\n",
    "merged_dfs['pantro_ensembl'].columns = ['gene_name', 'panTro4 (Ensembl V90)']\n",
    "#merged_dfs['ponabe_ensembl'].columns = ['gene_name', 'ponAbe2 (Ensembl V90)']\n",
    "merged_dfs['gorgor3_ensembl'].columns = ['gene_name', 'gorGor3 (Ensembl V90)']\n",
    "merged_dfs['panTro4'].columns = ['gene_name', 'panTro4 (CAT)']\n",
    "#merged_dfs['ponAbe2'].columns = ['gene_name', 'ponAbe2 (CAT)']\n",
    "merged_dfs['gorGor4'].columns = ['gene_name', 'gorGor4 (CAT)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we merge and group\n",
    "combined_dfs = {}\n",
    "combined_dfs['chimp'] = merged_dfs['human'].merge(merged_dfs['chimp'], how='outer', on='gene_name').merge(merged_dfs['panTro4'], how='outer', on='gene_name').merge(merged_dfs['pantro_ensembl'], how='outer', on='gene_name')\n",
    "combined_dfs['gorilla'] = merged_dfs['human'].merge(merged_dfs['gorilla'], how='outer', on='gene_name').merge(merged_dfs['gorGor4'], how='outer', on='gene_name').merge(merged_dfs['gorgor3_ensembl'], how='outer', on='gene_name')\n",
    "#combined_dfs['orangutan'] = merged_dfs['human'].merge(merged_dfs['orangutan'], how='outer', on='gene_name').merge(merged_dfs['ponAbe2'], how='outer', on='gene_name').merge(merged_dfs['ponabe_ensembl'], how='outer', on='gene_name')\n",
    "\n",
    "melted_dfs = {}\n",
    "for g, df in combined_dfs.iteritems():\n",
    "    df = pd.melt(df, id_vars=['gene_name', 'Human (GENCODE V27)'])\n",
    "    df.columns = ['gene_name', 'Human (GENCODE V27)', 'assembly/annotation', 'TPM']\n",
    "    melted_dfs[g] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_fn(pdf, df, cols, num_human, num_cat, num_old_cat, num_ensembl):\n",
    "    palette = sns.color_palette()\n",
    "    #palette = [palette[3], palette[2], palette[1]]\n",
    "    palette = palette[1:]\n",
    "    with open(pdf, 'w') as outf, PdfPages(outf) as pdf:\n",
    "        g = sns.lmplot(data=df, x='Human (GENCODE V27)', y='TPM', col='assembly/annotation',\n",
    "                      hue='assembly/annotation', fit_reg=False,\n",
    "                      scatter_kws={'marker': '+', 'alpha': 0.5, 's': 3,  'rasterized': True},\n",
    "                      col_order=cols,\n",
    "                      palette=palette)\n",
    "        x = np.linspace(0, 250)\n",
    "        for col, ax in zip(*[cols, g.axes[0]]):\n",
    "            tmp = df[df['assembly/annotation'] == col]\n",
    "            tmp = tmp[(tmp['Human (GENCODE V27)'].notnull()) & (tmp['TPM'].notnull())]\n",
    "            c, p = pearsonr(tmp['Human (GENCODE V27)'], tmp['TPM'])\n",
    "            ax.set_title(ax.get_title() + '\\nPearson r={:.2f} p={:.2f}'.format(c, p))\n",
    "            ax.set_xlim(0, 250)\n",
    "            ax.set_ylim(0, 250)\n",
    "            ax.plot(x, x, 'r--', color='black', alpha=0.7, linewidth=1)\n",
    "        multipage_close(pdf, False)\n",
    "        g = sns.barplot(x=['Human (GENCODE V27)'] + cols,\n",
    "                   y=[num_human, num_cat, num_old_cat, num_ensembl])\n",
    "        g.set_title('Number of genes found in RNA-seq')\n",
    "        sns.despine()\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.title('Number of genes with non-zero expression')\n",
    "        multipage_close(pdf, False)\n",
    "        \n",
    "\n",
    "import seaborn as sns\n",
    "from cat.plots import *\n",
    "from scipy.stats import *\n",
    "hdf =  merged_dfs['human']\n",
    "num_human = len(hdf[hdf['Human (GENCODE V27)'] > 0.1])\n",
    "for g, df in melted_dfs.iteritems():\n",
    "    pdf = g + '.pdf'\n",
    "    if g == 'chimp':\n",
    "        cols = ['Clint/Chimpanzee (CAT)', 'panTro4 (CAT)', 'panTro4 (Ensembl V90)']\n",
    "    elif g == 'gorilla':\n",
    "        cols = ['Susie/Gorilla (CAT)', 'gorGor4 (CAT)', 'gorGor3 (Ensembl V90)']\n",
    "    else:\n",
    "        cols = ['Susie/Orangutan (CAT)', 'ponAbe2 (CAT)', 'ponAbe2 (Ensembl V90)']\n",
    "    if g == 'chimp':\n",
    "        num_cat = len(merged_dfs['chimp'][merged_dfs['chimp']['Clint/Chimpanzee (CAT)'] > 0.1])\n",
    "        num_old_cat = len(merged_dfs['panTro4'][merged_dfs['panTro4']['panTro4 (CAT)'] > 0.1])\n",
    "        num_ensembl = len(merged_dfs['pantro_ensembl'][merged_dfs['pantro_ensembl']['panTro4 (Ensembl V90)'] > 0.1])\n",
    "    elif g == 'gorilla':\n",
    "        num_cat = len(merged_dfs['gorilla'][merged_dfs['gorilla']['Susie/Gorilla (CAT)'] > 0.1])\n",
    "        num_old_cat = len(merged_dfs['gorGor4'][merged_dfs['gorGor4']['gorGor4 (CAT)'] > 0.1])\n",
    "        num_ensembl = len(merged_dfs['gorgor3_ensembl'][merged_dfs['gorgor3_ensembl']['gorGor3 (Ensembl V90)'] > 0.1])\n",
    "    else:\n",
    "        num_cat = len(merged_dfs['orangutan'][merged_dfs['orangutan']['Susie/Orangutan (CAT)'] > 0.1])\n",
    "        num_old_cat = len(merged_dfs['ponAbe2'][merged_dfs['ponAbe2']['ponAbe2 (CAT)'] > 0.1])\n",
    "        num_ensembl = len(merged_dfs['ponabe_ensembl'][merged_dfs['ponabe_ensembl']['ponAbe2 (Ensembl V90)'] > 0.1])\n",
    "    plot_fn(pdf, df, cols, num_human, num_cat, num_old_cat, num_ensembl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
