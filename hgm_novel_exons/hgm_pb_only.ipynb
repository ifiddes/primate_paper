{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tools.procOps import *\n",
    "from tools.fileOps import *\n",
    "import pandas as pd\n",
    "from cat.hints_db import *\n",
    "from tools.misc import *\n",
    "from tools.intervals import *\n",
    "from tools.transcripts import *\n",
    "import itertools\n",
    "import re\n",
    "from cat.hgm import extract_exon_hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to run homGeneMapping, I need to use the existing hints database which contains the IsoSeq hints\n",
    "\n",
    "# for each genome, I construct a reference GTF consisting of ab-initio exons and CDS\n",
    "# I then lift them over to target genomes\n",
    "\n",
    "# we want to use both CDS and exon intervals because CGP has a coding-only model, and so the CDS interval\n",
    "# will be the exonic interval\n",
    "\n",
    "# I also construct a supplemental GFF that consists of the transMap exons (or gencode for human)\n",
    "# these will let me know which exons are novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gencode_gp = '../../reference/gencode.v27.annotation.no_PAR.gp'\n",
    "\n",
    "def gene_pred_to_gtf(tx):\n",
    "    \"\"\"Extract both exons and CDS intervals as CDS\"\"\"\n",
    "    for exon in tx.exon_intervals:\n",
    "        yield [tx.chromosome, 'CAT', 'exon', exon.start + 1, exon.stop, '.', exon.strand, '.', 'transcript_id \"{}; gene_id \"{}\"'.format(tx.name, tx.name2)]\n",
    "    cds_tx = Transcript(tx.get_bed(new_start=tx.thick_start, new_stop=tx.thick_stop))\n",
    "    for exon in cds_tx.exon_intervals:\n",
    "        yield [tx.chromosome, 'CAT', 'exon', exon.start + 1, exon.stop, '.', exon.strand, '.', 'transcript_id \"{}_cds\"; gene_id \"{}\"'.format(tx.name, tx.name2)]\n",
    "        \n",
    "def gene_pred_to_gff(tx):\n",
    "    \"\"\"Extract both exons and CDS intervals as CDS\"\"\"\n",
    "    for exon in tx.exon_intervals:\n",
    "        yield [tx.chromosome, 'CAT', 'exon', exon.start + 1, exon.stop, '.', exon.strand, '.', 'source=A']\n",
    "    cds_tx = Transcript(tx.get_bed(new_start=tx.thick_start, new_stop=tx.thick_stop))\n",
    "    for exon in cds_tx.exon_intervals:\n",
    "        yield [tx.chromosome, 'CAT', 'exon', exon.start + 1, exon.stop, '.', exon.strand, '.', 'source=A']\n",
    "        \n",
    "\n",
    "with open('gtfs.tbl', 'w') as outf:\n",
    "    for genome in ['Human', 'Clint_Chimp', 'Susie_Gorilla', 'Susie_Orangutan']:\n",
    "        # isolate ab-initio transcripts that are spliced\n",
    "        cgp_gp = '../../augustus_cgp/{}.augCGP.gp'.format(genome)\n",
    "        pb_gp = '../../augustus_pb/{}.augPB.gp'.format(genome)\n",
    "        out_gtf = genome + '.ab_initio_exons.gtf'\n",
    "        with open(out_gtf, 'w') as out_gtf_handle:\n",
    "            for gp in [cgp_gp, pb_gp]:\n",
    "                for tx in gene_pred_iterator(gp):\n",
    "                    if len(tx.intron_intervals) > 0:\n",
    "                        print_rows(out_gtf_handle, list(gene_pred_to_gtf(tx)))\n",
    "        supp_gff = genome + '.extrinsic_supplement.gff'\n",
    "        with open(supp_gff, 'w') as supp_gff_handle:\n",
    "            # copy all transMap or GENCODE exons with source=A to the supplement\n",
    "            if genome == 'Human':\n",
    "                annot_gp = gencode_gp\n",
    "            else:\n",
    "                annot_gp = '../../transMap/{}.gp'.format(genome)\n",
    "            for tx in gene_pred_iterator(annot_gp):\n",
    "                print_rows(supp_gff_handle, list(gene_pred_to_gff(tx)))\n",
    "        print_row(outf, [genome, out_gtf, supp_gff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halLiftover starts. Processing\n",
      "Clint_Chimp\n",
      "Human\n",
      "Susie_Gorilla\n",
      "Susie_Orangutan\n"
     ]
    }
   ],
   "source": [
    "!homGeneMapping --halfile=../../v2_chimp_orang.hal --gtfs=gtfs.tbl --cpus=32 --dbaccess=../../hints_database/hints.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load HGM output\n",
    "parsed_hgm = {}\n",
    "r = re.compile('\\**-')\n",
    "species_map = {'0': 'Clint_Chimp', '1': 'Human', '2': 'Susie_Gorilla', '3': 'Susie_Orangutan'}\n",
    "\n",
    "def parse_info_line(hgm_info):\n",
    "    \"\"\"\n",
    "    For a given info line, we want to know what genomes it was supported in, and at what level\n",
    "    \n",
    "    Returns a dict with key-values of PB/N/M, etc, value is multiplicity\n",
    "    \"\"\"\n",
    "    ret_dict = {}  # keeps mapping of genome name to values\n",
    "    for l in hgm_info.split(','):\n",
    "        ret = {}\n",
    "        if 'PB' in l or 'A' in l:  # make sure we have something to look at\n",
    "            g = species_map[l[0]]\n",
    "            sl = l[1:].split(':')  # strip species identifier\n",
    "            for v in sl:\n",
    "                if '-' in v:\n",
    "                    feature_type, mult = r.split(v)\n",
    "                    ret[feature_type] = int(mult)\n",
    "                else:\n",
    "                    ret[v] = 1\n",
    "            ret_dict[g] = ret\n",
    "    return ret_dict\n",
    "\n",
    "for g in ['Human', 'Clint_Chimp', 'Susie_Gorilla', 'Susie_Orangutan']:\n",
    "    e = []\n",
    "    with open(g + '.gtf') as infile:\n",
    "        for line in infile:\n",
    "            if '\\texon\\t' in line:\n",
    "                line = line.rstrip().split('\\t')\n",
    "                attr_line = line[-1]\n",
    "                attributes = parse_gtf_attr_line(attr_line)\n",
    "                data = parse_info_line(attributes['hgm_info'])\n",
    "                i = ChromosomeInterval(line[0], int(line[3]) - 1, int(line[4]), '.', data)\n",
    "                e.append([i, attributes['transcript_id'].split('_')[0]])\n",
    "    parsed_hgm[g] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supported_dfs = {}\n",
    "features = ['PB', 'A']\n",
    "cols = ['ab_initio_tx_id', 'chromosome', 'start', 'stop']\n",
    "for g in ['Human', 'Clint_Chimp', 'Susie_Gorilla', 'Susie_Orangutan']:\n",
    "    for m in features:\n",
    "        cols.append(g + '_' + m)\n",
    "\n",
    "for genome, e in parsed_hgm.iteritems():\n",
    "    df = []  # dataframe with values chromosome, start, stop, then genome support levels in order\n",
    "    for i, tx_id in e:\n",
    "        # filter out poorly annotated human sequences\n",
    "        if genome == 'Human' and ('alt' in i.chromosome or 'random' in i.chromosome or 'chrUn' in i.chromosome):\n",
    "            continue\n",
    "        r = [tx_id, i.chromosome, i.start, i.stop]  # row\n",
    "        for g in ['Human', 'Clint_Chimp', 'Susie_Gorilla', 'Susie_Orangutan']:\n",
    "            for m in features:\n",
    "                if g in i.data:\n",
    "                    r.append(i.data[g].get(m, 0))\n",
    "                else:\n",
    "                    r.append(0)\n",
    "        df.append(r)\n",
    "    \n",
    "    df = pd.DataFrame(df, columns=cols)\n",
    "    supported_dfs[genome] = df.drop_duplicates()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load gene info for output\n",
    "genomes = ['Clint_Chimp', 'Susie_Gorilla', 'Susie_Orangutan']\n",
    "annotation_maps = {}\n",
    "for genome in genomes:\n",
    "    df = pd.read_csv(os.path.join('../../consensus_gene_set', genome + '.gp_info'), sep='\\t')\n",
    "    df = df[['alignment_id', 'source_gene', 'source_gene_common_name']]\n",
    "    df.columns = ['ab_initio_tx_id', 'gene_id', 'gene_name']\n",
    "    annotation_maps[genome] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform parent gene assignment on Human\n",
    "from cat.parent_gene_assignment import assign_parents\n",
    "parents = []\n",
    "for d in ['../../augustus_cgp/Human.augCGP.gp', '../../augustus_pb/Human.augPB.gp']:\n",
    "    tx_dict = get_gene_pred_dict(d)\n",
    "    tx_dict = {tx_id: tx for tx_id, tx in tx_dict.iteritems() if len(tx.exon_intervals) > 1}\n",
    "    # abuse parental assignment code by passing reference as unfiltered and filtered transMap\n",
    "    parents.append(assign_parents('../../reference/gencode.v27.annotation.no_PAR.gp', \n",
    "                                  '../../reference/gencode.v27.annotation.no_PAR.gp', \n",
    "                                  '../../genome_files/Human.chrom.sizes', d))\n",
    "assignment_df = pd.concat(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools.sqlInterface import *\n",
    "ref_df = load_annotation('../../databases/Human.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "human_df = assignment_df.reset_index().merge(ref_df, left_on='AssignedGeneId', right_on='GeneId')\n",
    "human_df = human_df[['TranscriptId_x', 'GeneId', 'GeneName']]\n",
    "human_df.columns = ['ab_initio_tx_id', 'gene_id', 'gene_name']\n",
    "annotation_maps['Human'] = human_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strict_novel_exon_dfs = {}\n",
    "for g, df in supported_dfs.iteritems():\n",
    "    subset_df = df[(df['{}_PB'.format(g)] > 0) & (df['Human_A'] == 0) & (df['Clint_Chimp_A'] == 0) & (df['Susie_Gorilla_A'] == 0) & (df['Susie_Orangutan_A'] == 0)]\n",
    "    subset_df = subset_df.merge(annotation_maps[g], on='ab_initio_tx_id')\n",
    "    subset_df = subset_df.drop(['Clint_Chimp_A', 'Human_A', 'Susie_Gorilla_A', 'Susie_Orangutan_A'], axis=1)\n",
    "    # drop duplicates\n",
    "    subset_df = subset_df.groupby(['chromosome', 'start', 'stop']).first().reset_index()\n",
    "    subset_df.to_csv('{}.txt'.format(g), sep='\\t', index=False)\n",
    "    strict_novel_exon_dfs[g] = subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each, how many have support in others?\n",
    "# unroll\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib_venn import *\n",
    "import matplotlib.pyplot as plt\n",
    "genomes = ['Human', 'Clint_Chimp', 'Susie_Gorilla', 'Susie_Orangutan']\n",
    "def unroll_df(df, g):\n",
    "    other_genomes = set(genomes) - {g}\n",
    "    results = defaultdict(set)\n",
    "    singletons = 0\n",
    "    for i, s in df.iterrows():\n",
    "        if all(s['{}_PB'.format(og)] == 0 for og in other_genomes):\n",
    "            singletons += 1\n",
    "            continue\n",
    "        for og in other_genomes:\n",
    "            if s['{}_PB'.format(og)] > 0:\n",
    "                results[og].add(i)\n",
    "    return results, singletons\n",
    "\n",
    "from cat.plots import *\n",
    "with open('novel_exon_cross_species_support.pdf', 'w') as outf, PdfPages(outf) as pdf:\n",
    "    for g, df in strict_novel_exon_dfs.iteritems():\n",
    "        fig, ax = plt.subplots()\n",
    "        results, singletons = unroll_df(df, g)\n",
    "        x = sorted(results.items())\n",
    "        names, vals = zip(*x)\n",
    "        v = venn3(vals, set_labels=names, ax=ax)\n",
    "        ax.set_title('{} novel exons supported by IsoSeq in other genomes\\nwith {:,} species-specific exons'.format(g, singletons))\n",
    "        multipage_close(pdf, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many of the strict set have no overlap with any comparative exon?\n",
    "for genome, df in strict_novel_exon_dfs.iteritems():\n",
    "    df[['chromosome', 'start', 'stop']].to_csv('{}.bed'.format(genome), sep='\\t', header=None, index=False)\n",
    "    with TemporaryFilePath() as tmp_annotation_bed, TemporaryFilePath() as tmp_annotation_bed_flat:\n",
    "        if genome == 'Human':\n",
    "            !cp '../../reference/gencode.v27.annotation.no_PAR.bed' {tmp_annotation_bed}\n",
    "        else:\n",
    "            !genePredToBed ../../transMap/{genome}.gp {tmp_annotation_bed}\n",
    "        # flatten annotation to split apart exons for intersection\n",
    "        !bedtools bed12tobed6 -i {tmp_annotation_bed} > {tmp_annotation_bed_flat}\n",
    "        !bedSort {tmp_annotation_bed_flat} {tmp_annotation_bed_flat}\n",
    "        # find complement of intersection of flat per-exon BED with novel calls\n",
    "        !bedtools intersect -v -a {genome}.bed -b {tmp_annotation_bed_flat} > {genome}.no_overlap.txt\n",
    "        # find intersection of the above with extant loci (how many novel exons are within an annotated gene)\n",
    "        !bedtools intersect -u -a {genome}.no_overlap.txt -b {tmp_annotation_bed} > {genome}.no_overlap.extant_only.txt\n",
    "        # re-add columns\n",
    "        for x in ['.no_overlap.extant_only.txt', '.no_overlap.txt']:\n",
    "            p = genome + x\n",
    "            tmp_df = pd.read_csv(p, sep='\\t', header=None)\n",
    "            tmp_df.columns = ['chromosome', 'start', 'stop']\n",
    "            tmp_df = tmp_df.merge(df, on=['chromosome', 'start', 'stop'])\n",
    "            tmp_df.to_csv(p, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cat.plots import *\n",
    "with open('novel_exon_cross_species_support_no_splice_shift.pdf', 'w') as outf, PdfPages(outf) as pdf:\n",
    "    for g in strict_novel_exon_dfs:\n",
    "        if g == 'Human':\n",
    "            continue\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "        for x, ax in zip(*[['.no_overlap.extant_only.txt', '.no_overlap.txt'], [ax1, ax2]]):\n",
    "            p = g + x\n",
    "            df = pd.read_csv(p, sep='\\t')\n",
    "            results, singletons = unroll_df(df, g)\n",
    "            d = sorted(results.items())\n",
    "            names, vals = zip(*d)\n",
    "            v = venn3(vals, set_labels=names, ax=ax)\n",
    "            if x == '.no_overlap.extant_only.txt':\n",
    "                ax.set_title('Novel exons in annotated loci\\n{:,} species-specific exons'.format(singletons))\n",
    "            else:\n",
    "                ax.set_title('All novel exons\\n{:,} species-specific exons'.format(singletons))\n",
    "        fig.suptitle(g)\n",
    "        multipage_close(pdf, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            genome  Novel splices  Novel exons  \\\n",
      "0      Clint_Chimp            477          305   \n",
      "2            Human             96           50   \n",
      "3    Susie_Gorilla             81          248   \n",
      "1  Susie_Orangutan            407          229   \n",
      "\n",
      "   Novel exons in previously annotated loci  \n",
      "0                                       173  \n",
      "2                                         7  \n",
      "3                                        18  \n",
      "1                                       164  \n"
     ]
    }
   ],
   "source": [
    "rdf = []\n",
    "for g in strict_novel_exon_dfs:\n",
    "    tot = len(open(g + '.txt').readlines())\n",
    "    exon = len(open(g + '.no_overlap.txt').readlines())\n",
    "    loci = len(open(g + '.no_overlap.extant_only.txt').readlines())\n",
    "    rdf.append([g, tot - (exon + loci), exon - loci, loci])\n",
    "    \n",
    "rdf = pd.DataFrame(rdf, columns=['genome', 'Novel splices', 'Novel exons', 'Novel exons in previously annotated loci'])\n",
    "print rdf.sort_values('genome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clint_Chimp 624 174 Counter({u'protein_coding': 600, u'lincRNA': 7, u'antisense_RNA': 5, u'processed_transcript': 5, u'transcribed_unprocessed_pseudogene': 3, u'unprocessed_pseudogene': 1, u'sense_overlapping': 1, u'transcribed_processed_pseudogene': 1, u'transcribed_unitary_pseudogene': 1})\n",
      "Susie_Orangutan 545 139 Counter({u'protein_coding': 511, u'unprocessed_pseudogene': 13, u'antisense_RNA': 6, u'transcribed_unprocessed_pseudogene': 6, u'processed_transcript': 5, u'lincRNA': 2, u'transcribed_processed_pseudogene': 1, u'processed_pseudogene': 1})\n",
      "Human 103 56 Counter({u'protein_coding': 101, u'transcribed_processed_pseudogene': 1, u'lincRNA': 1})\n",
      "Susie_Gorilla 84 68 Counter({u'protein_coding': 75, u'unprocessed_pseudogene': 3, u'sense_overlapping': 3, u'lincRNA': 1, u'transcribed_unprocessed_pseudogene': 1, u'transcribed_unitary_pseudogene': 1})\n"
     ]
    }
   ],
   "source": [
    "# Evan wants me to add information on how many amino acids these add.\n",
    "\n",
    "# I also realized I am double counting events\n",
    "\n",
    "ref_tmp = ref_df[['GeneId', 'GeneBiotype']]\n",
    "ref_tmp.columns = ['gene_id', 'gene_biotype']\n",
    "ref_tmp = ref_tmp.drop_duplicates()\n",
    "# just load from the disk\n",
    "\n",
    "novel_dfs = {}\n",
    "for g in strict_novel_exon_dfs:\n",
    "    splices = pd.read_csv(g + '.txt', sep='\\t')\n",
    "    exon = pd.read_csv(g + '.no_overlap.txt', sep='\\t')\n",
    "    # remove exon from splices\n",
    "    tmp = splices.merge(exon, how='outer', indicator=True)\n",
    "    splices = tmp[tmp['_merge'] == 'left_only'].drop('_merge', axis=1).merge(ref_tmp, on='gene_id')\n",
    "    exon = exon.merge(ref_tmp, on='gene_id')\n",
    "    novel_dfs[g] = [splices, exon]\n",
    "    print g, len(splices), len(exon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_dicts = {}\n",
    "for g in novel_dfs.iteritems():\n",
    "    if g == 'Human':\n",
    "        tx_dicts[g] = get_gene_pred_dict('/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/reference/gencode.v27.annotation.no_PAR.gp')\n",
    "    else:\n",
    "        tx_dicts[g] = get_gene_pred_dict('/hive/groups/recon/projs/primates/primates_indel_corrected_bionano_cut/consensus_gene_set/{}.gp'.format(g))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for g, (splices, exon) in novel_dfs.iteritems():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
